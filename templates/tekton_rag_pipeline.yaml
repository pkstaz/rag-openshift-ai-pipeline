apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: {{ .Values.pipelineName }}
  namespace: {{ .Values.namespace }}
spec:
  params:
  - name: minio-endpoint
    default: "{{ .Values.minioEndpoint }}"
  - name: minio-access-key
    default: "{{ .Values.minioAccessKey }}"
  - name: minio-secret-key
    default: "{{ .Values.minioSecretKey }}"
  - name: bucket-name
    default: "{{ .Values.bucketName }}"
  - name: object-key
    default: "{{ .Values.objectKey }}"
  - name: chunk-size
    default: "{{ .Values.chunkSize }}"
  - name: chunk-overlap
    default: "{{ .Values.chunkOverlap }}"
  - name: elasticsearch-endpoint
    default: "{{ .Values.elasticsearchEndpoint }}"
  - name: elasticsearch-username
    default: "{{ .Values.elasticsearchUsername }}"
  - name: elasticsearch-password
    default: "{{ .Values.elasticsearchPassword }}"

  tasks:
  - name: validate-connections
    taskSpec:
      params:
      - name: minio-endpoint
      - name: minio-access-key
      - name: minio-secret-key
      - name: elasticsearch-endpoint
      - name: elasticsearch-username
      - name: elasticsearch-password
      steps:
      - name: validate
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          import os
          os.system("pip install --quiet minio requests")
          from minio import Minio
          import requests

          print("üîé Validating connection to MinIO...")
          minio_endpoint = "$(params.minio-endpoint)"
          minio_access_key = "$(params.minio-access-key)"
          minio_secret_key = "$(params.minio-secret-key)"
          try:
              minio_client = Minio(
                  minio_endpoint,
                  access_key=minio_access_key,
                  secret_key=minio_secret_key,
                  secure=True
              )
              buckets = minio_client.list_buckets()
              print(f"‚úÖ Connection successful to MinIO. Buckets: {[b.name for b in buckets]}")
          except Exception as e:
              print(f"‚ùå ERROR connecting to MinIO: {e}")
              exit(1)

          print("üîé Validating connection to Elasticsearch...")
          es_endpoint = "$(params.elasticsearch-endpoint)"
          es_user = "$(params.elasticsearch-username)"
          es_pass = "$(params.elasticsearch-password)"
          print(f"[DEBUG] Actual es_endpoint value: {es_endpoint}")
          if es_user and es_pass:
              auth = (es_user, es_pass)
          else:
              auth = None
          try:
              resp = requests.get(es_endpoint, auth=auth, timeout=5, verify=False)
              print(f"‚úÖ Connection successful to Elasticsearch. Status: {resp.status_code}")
              print(f"Response: {resp.text[:200]}")
          except Exception as e:
              print(f"‚ùå ERROR connecting to Elasticsearch: {e}")
              exit(1)
    params:
    - name: minio-endpoint
      value: {{ .Values.minioEndpoint }}
    - name: minio-access-key
      value: {{ .Values.minioAccessKey }}
    - name: minio-secret-key
      value: {{ .Values.minioSecretKey }}
    - name: elasticsearch-endpoint
      value: {{ .Values.elasticsearchEndpoint | quote }}
    - name: elasticsearch-username
      value: {{ .Values.elasticsearchUsername | quote }}
    - name: elasticsearch-password
      value: {{ .Values.elasticsearchPassword | quote }}

  - name: extract-text
    runAfter: ["validate-connections"]
    taskSpec:
      params:
      - name: minio-endpoint
      - name: minio-access-key
      - name: minio-secret-key
      - name: bucket-name
      - name: object-key
      results:
      - name: text-content
        description: Extracted text content
      steps:
      - name: extract
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          
          import sys
          import tempfile
          import os
          
          print("üöÄ Starting text extraction...")
          print(f"üìä Python version: {sys.version}")
          
          # Install required packages
          print("üì¶ Installing dependencies...")
          os.system("pip install --quiet minio requests")
          
          from minio import Minio
          
          try:
              print("üîó Connecting to MinIO...")
              print(f"Endpoint: $(params.minio-endpoint)")
              print(f"Bucket: $(params.bucket-name)")
              print(f"Object: $(params.object-key)")
              
              # Connect to MinIO
              minio_client = Minio(
                  "$(params.minio-endpoint)",
                  access_key="$(params.minio-access-key)",
                  secret_key="$(params.minio-secret-key)",
                  secure=True
              )
              
              # Test connection
              print("üß™ Testing MinIO connection...")
              try:
                  buckets = list(minio_client.list_buckets())
                  print(f"‚úÖ Connected! Found {len(buckets)} buckets")
                  for bucket in buckets:
                      print(f"  - {bucket.name}")
              except Exception as e:
                  print(f"‚ö†Ô∏è Warning: Could not list buckets: {e}")
              
              # Download file
              print("üì• Downloading file...")
              with tempfile.NamedTemporaryFile(delete=False, suffix='.txt') as temp_file:
                  temp_path = temp_file.name
              
              minio_client.fget_object("$(params.bucket-name)", "$(params.object-key)", temp_path)
              print(f"‚úÖ File downloaded to: {temp_path}")
              
              # Read content
              print("üìñ Reading file content...")
              with open(temp_path, 'r', encoding='utf-8', errors='replace') as f:
                  content = f.read()
              
              # Clean up
              os.unlink(temp_path)
              
              print(f"‚úÖ Text extracted: {len(content)} characters")
              print(f"üìù Content preview: {content[:100]}...")
              
              # Ensure results directory exists
              os.makedirs("/tekton/results", exist_ok=True)
              
              # Write result to Tekton results
              result_path = "/tekton/results/text-content"
              with open(result_path, "w", encoding='utf-8') as f:
                  f.write(content)
              
              print(f"‚úÖ Result written to: {result_path}")
              print(f"üìä Result file size: {os.path.getsize(result_path)} bytes")
                  
          except Exception as e:
              print(f"‚ùå Error in extraction: {str(e)}")
              import traceback
              traceback.print_exc()
              
              # Write error as result
              os.makedirs("/tekton/results", exist_ok=True)
              error_msg = f"Error extracting text: {str(e)}"
              with open("/tekton/results/text-content", "w") as f:
                  f.write(error_msg)
              
              # Don't fail the task, just log the error
              print("‚ö†Ô∏è Error logged to results, continuing...")
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 200m
    params:
    - name: minio-endpoint
      value: $(params.minio-endpoint)
    - name: minio-access-key
      value: $(params.minio-access-key)
    - name: minio-secret-key
      value: $(params.minio-secret-key)
    - name: bucket-name
      value: $(params.bucket-name)
    - name: object-key
      value: $(params.object-key)

  - name: chunk-text
    runAfter: ["extract-text"]
    taskSpec:
      params:
      - name: text-content
        description: Text content from previous task
      - name: chunk-size
      - name: chunk-overlap
      results:
      - name: chunks-json
        description: JSON with text chunks
      steps:
      - name: chunk
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          
          import json
          import sys
          import os
          import base64
          
          print("üöÄ Starting chunking process...")
          print(f"üìä Python version: {sys.version}")
          
          # Get text content from parameter (passed from previous task)
          text_content = """$(params.text-content)"""
          
          print(f"üìù Received text length: {len(text_content)} characters")
          print(f"üìÑ Text preview: {text_content[:200]}...")
          
          try:
              chunk_size = int("$(params.chunk-size)")
              chunk_overlap = int("$(params.chunk-overlap)")
              
              print(f"‚öôÔ∏è Chunk size: {chunk_size}")
              print(f"‚öôÔ∏è Chunk overlap: {chunk_overlap}")
              
              if not text_content or text_content.strip() == "":
                  print("‚ö†Ô∏è Empty text content received")
                  chunks = []
              elif text_content.startswith("Error"):
                  print("‚ö†Ô∏è Error in previous task, creating error chunk")
                  chunks = [{
                      "chunk_id": "chunk_error",
                      "text": text_content,
                      "char_count": len(text_content),
                      "error": True
                  }]
              else:
                  # Chunking logic
                  max_chars = chunk_size * 4  # Conservative estimate
                  overlap_chars = chunk_overlap * 4
                  
                  chunks = []
                  start = 0
                  chunk_id = 0
                  
                  print(f"üîß Calculated max_chars: {max_chars}, overlap_chars: {overlap_chars}")
                  
                  while start < len(text_content):
                      end = min(start + max_chars, len(text_content))
                      chunk_text = text_content[start:end]
                      
                      # Find good cut point at word boundary
                      if end < len(text_content):
                          space_pos = chunk_text.rfind(' ', int(len(chunk_text) * 0.8))
                          if space_pos > 0:
                              chunk_text = chunk_text[:space_pos]
                              end = start + space_pos
                      
                      chunk_text = chunk_text.strip()
                      if len(chunk_text) > 10:  # Skip very small chunks
                          chunk_data = {
                              "chunk_id": f"chunk_{chunk_id:04d}",
                              "text": chunk_text,
                              "char_count": len(chunk_text),
                              "start_pos": start,
                              "end_pos": start + len(chunk_text)
                          }
                          chunks.append(chunk_data)
                          chunk_id += 1
                          print(f"‚úÖ Created chunk {chunk_id}: {len(chunk_text)} chars")
                      
                      if end >= len(text_content):
                          break
                      start = max(end - overlap_chars, start + 1)
              
              # CREATE THE RESULT VARIABLE - This was missing!
              result = json.dumps(chunks, ensure_ascii=False)
              print(f"‚úÖ Created JSON result with {len(chunks)} chunks")
              
              # Encode result in base64 to avoid JSON control character issues
              result_b64 = base64.b64encode(result.encode('utf-8')).decode('ascii')
              
              # Write base64 encoded result
              os.makedirs("/tekton/results", exist_ok=True)
              result_path = "/tekton/results/chunks-json"
              with open(result_path, "w", encoding='utf-8') as f:
                  f.write(result_b64)
              
              print(f"‚úÖ Chunks written to: {result_path}")
              print(f"üìä Result size: {len(result)} characters")
              print(f"üìä Base64 size: {len(result_b64)} characters")
                  
          except Exception as e:
              print(f"‚ùå Error in chunking: {str(e)}")
              import traceback
              traceback.print_exc()
              
              # Fallback chunk with base64 encoding
              fallback = [{
                  "chunk_id": "chunk_error_0000",
                  "text": text_content[:1000] if text_content else "No content available",
                  "char_count": len(text_content[:1000]) if text_content else 0,
                  "error": True,
                  "error_message": str(e)
              }]
              
              fallback_result = json.dumps(fallback, ensure_ascii=False)
              fallback_b64 = base64.b64encode(fallback_result.encode('utf-8')).decode('ascii')
              
              os.makedirs("/tekton/results", exist_ok=True)
              with open("/tekton/results/chunks-json", "w") as f:
                  f.write(fallback_b64)
              
              print("‚ö†Ô∏è Fallback chunk created")
        resources:
          requests:
            memory: 128Mi
            cpu: 50m
          limits:
            memory: 256Mi
            cpu: 100m
    params:
    - name: text-content
      value: $(tasks.extract-text.results.text-content)
    - name: chunk-size
      value: $(params.chunk-size)
    - name: chunk-overlap
      value: $(params.chunk-overlap)

  - name: generate-embeddings
    runAfter: ["chunk-text"]
    taskSpec:
      params:
      - name: chunks-json
        description: JSON with chunks from previous task
      - name: minio-endpoint
      - name: minio-access-key
      - name: minio-secret-key
      - name: object-key
      results:
      - name: status
        description: Processing status
      steps:
      - name: embed
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          
          import json
          import sys
          import os
          import base64
          import tempfile
          from datetime import datetime
          
          print("üöÄ Starting embedding generation...")
          print(f"üìä Python version: {sys.version}")
          
          # Install required packages
          print("üì¶ Installing dependencies...")
          os.system("pip install --quiet sentence-transformers torch numpy minio")
          
          from sentence_transformers import SentenceTransformer
          import torch
          from minio import Minio
          
          # Get chunks from parameter - decode base64
          chunks_json_b64 = "$(params.chunks-json)"
          
          print(f"üìù Received base64 chunks length: {len(chunks_json_b64)} characters")
          
          try:
              # Decode from base64
              chunks_json = base64.b64decode(chunks_json_b64).decode('utf-8')
              print(f"üìù Decoded JSON length: {len(chunks_json)} characters")
              
              chunks = json.loads(chunks_json)
              print(f"üìä Processing {len(chunks)} chunks")
              
              # Connect to MinIO for result storage
              print("üîó Connecting to MinIO for result storage...")
              minio_client = Minio(
                  "$(params.minio-endpoint)",
                  access_key="$(params.minio-access-key)",
                  secret_key="$(params.minio-secret-key)",
                  secure=True
              )
              
              result_status = "success"
              
              if not chunks:
                  print("‚ö†Ô∏è No chunks to process")
                  result = json.dumps([])
                  result_status = "no_chunks"
              elif any(chunk.get('error', False) for chunk in chunks):
                  print("‚ö†Ô∏è Error chunks detected, skipping embedding generation")
                  result = chunks_json  # Pass through the error chunks
                  result_status = "error_chunks"
              else:
                  # Load model with CPU only to avoid GPU issues
                  device = 'cpu'
                  print(f"üß† Loading model on {device}...")
                  model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)
                  print(f"‚úÖ Model loaded successfully")
                  
                  # Generate embeddings
                  texts = [chunk['text'] for chunk in chunks]
                  print(f"üîÑ Generating embeddings for {len(texts)} texts...")
                  
                  embeddings = model.encode(
                      texts, 
                      convert_to_numpy=True, 
                      normalize_embeddings=True,
                      show_progress_bar=True,
                      batch_size=8  # Small batch size to avoid memory issues
                  )
                  
                  # Add embeddings to chunks
                  for i, chunk in enumerate(chunks):
                      chunk['embedding'] = embeddings[i].tolist()
                      chunk['embedding_dim'] = len(embeddings[i])
                      chunk['embedding_model'] = 'sentence-transformers/all-MiniLM-L6-v2'
                  
                  result = json.dumps(chunks, ensure_ascii=False, indent=2)
                  print(f"üéâ Successfully generated embeddings for {len(chunks)} chunks")
              
              # Save result to MinIO instead of Tekton results (too large)
              print(f"üì§ Uploading result to MinIO...")
              print(f"üìä Result size: {len(result)} characters ({len(result.encode('utf-8'))} bytes)")
              
              # Create filename based on original object
              original_object = "$(params.object-key)"
              timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
              result_filename = f"embeddings/{original_object}_{timestamp}_embeddings.json"
              
              # Upload to MinIO
              with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', delete=False) as temp_file:
                  temp_file.write(result)
                  temp_path = temp_file.name
              
              try:
                  minio_client.fput_object("processed-documents", result_filename, temp_path)
                  print(f"‚úÖ Result uploaded to MinIO: processed-documents/{result_filename}")
                  
                  # Clean up
                  os.unlink(temp_path)
                  
                  # Create small status result for Tekton
                  status_result = {
                      "status": result_status,
                      "chunks_processed": len(chunks),
                      "result_location": f"minio://processed-documents/{result_filename}",
                      "result_size_bytes": len(result.encode('utf-8')),
                      "timestamp": timestamp
                  }
                  
                  # Write small status to Tekton results (this will fit in 4KB limit)
                  os.makedirs("/tekton/results", exist_ok=True)
                  status_path = "/tekton/results/status"
                  with open(status_path, "w", encoding='utf-8') as f:
                      f.write(json.dumps(status_result, ensure_ascii=False))
                  
                  print(f"‚úÖ Status written to Tekton results: {status_path}")
                  print(f"üìä Status size: {len(json.dumps(status_result))} characters")
                  
              except Exception as upload_error:
                  print(f"‚ùå Error uploading to MinIO: {upload_error}")
                  os.unlink(temp_path)
                  raise upload_error
                  
          except Exception as e:
              print(f"‚ùå Error in embedding generation: {str(e)}")
              import traceback
              traceback.print_exc()
              
              # Fallback status
              fallback_status = {
                  "status": "error",
                  "error_message": str(e),
                  "chunks_processed": 0,
                  "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
              }
              
              os.makedirs("/tekton/results", exist_ok=True)
              with open("/tekton/results/status", "w") as f:
                  f.write(json.dumps(fallback_status, ensure_ascii=False))
              
              print("‚ö†Ô∏è Error status created")
        resources:
          requests:
            memory: 1Gi
            cpu: 200m
          limits:
            memory: 2Gi
            cpu: 500m
    params:
    - name: chunks-json
      value: $(tasks.chunk-text.results.chunks-json)
    - name: minio-endpoint
      value: $(params.minio-endpoint)
    - name: minio-access-key
      value: $(params.minio-access-key)
    - name: minio-secret-key
      value: $(params.minio-secret-key)
    - name: object-key
      value: $(params.object-key)

  - name: index-elasticsearch
    runAfter: ["generate-embeddings"]
    taskSpec:
      params:
      - name: minio-endpoint
      - name: minio-access-key
      - name: minio-secret-key
      - name: embeddings-status
        description: JSON de status de embeddings
      - name: elasticsearch-endpoint
        description: Endpoint de Elasticsearch
      - name: elasticsearch-username
        description: Usuario de Elasticsearch
      - name: elasticsearch-password
        description: Password de Elasticsearch
      steps:
      - name: index
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          import os
          os.system("pip install --quiet minio requests")
          import json
          import tempfile
          from minio import Minio
          import requests

          print("üöÄ Starting indexing in Elasticsearch...")

          # Par√°metros
          minio_endpoint = "$(params.minio-endpoint)"
          minio_access_key = "$(params.minio-access-key)"
          minio_secret_key = "$(params.minio-secret-key)"
          embeddings_status = '$(params.embeddings-status)'
          es_endpoint = "$(params.elasticsearch-endpoint)"
          es_user = "$(params.elasticsearch-username)"
          es_pass = "$(params.elasticsearch-password)"

          print(f"[DEBUG] embeddings_status recibido: {embeddings_status}")
          try:
              status_obj = json.loads(embeddings_status)
              embeddings_location = status_obj.get('result_location', '')
          except Exception as e:
              print(f"‚ùå ERROR: No se pudo parsear embeddings_status: {e}")
              exit(1)

          print(f"[DEBUG] embeddings_location extra√≠do: {embeddings_location}")
          if not embeddings_location.startswith("minio://"):
              print(f"‚ùå ERROR: embeddings_location no comienza con minio://. Valor recibido: {embeddings_location}")
              exit(1)

          # Parsear bucket y objeto de la URL minio://bucket/objeto
          path = embeddings_location.replace("minio://", "", 1)
          bucket, object_name = path.split("/", 1)

          # Definir auth para Elasticsearch
          if es_user and es_pass:
              auth = (es_user, es_pass)
          else:
              auth = None

          # Descargar archivo de embeddings desde MinIO
          minio_client = Minio(
              minio_endpoint,
              access_key=minio_access_key,
              secret_key=minio_secret_key,
              secure=True
          )
          with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as temp_file:
              temp_path = temp_file.name
          minio_client.fget_object(bucket, object_name, temp_path)
          print(f"‚úÖ Embeddings descargados: {temp_path}")

          # Leer embeddings
          with open(temp_path, 'r', encoding='utf-8') as f:
              embeddings = json.load(f)

          # Indexar en Elasticsearch
          headers = {"Content-Type": "application/json"}
          if es_user and es_pass:
              auth = (es_user, es_pass)
          else:
              auth = None

          index_name = "rag-documents"
          success = 0
          fail = 0
          for chunk in embeddings:
              doc_id = chunk.get("chunk_id")
              resp = requests.put(
                  f"{es_endpoint}/{index_name}/_doc/{doc_id}",
                  headers=headers,
                  data=json.dumps(chunk, ensure_ascii=False),
                  auth=auth,
                  verify=False
              )
              if resp.status_code in (200, 201):
                  print(f"‚úÖ Indexado: {doc_id}")
                  success += 1
              else:
                  print(f"‚ùå Error indexando {doc_id}: {resp.text}")
                  fail += 1
          print(f"üéâ Indexaci√≥n completa. Exitosos: {success}, Fallidos: {fail}")
    params:
    - name: minio-endpoint
      value: {{ .Values.minioEndpoint }}
    - name: minio-access-key
      value: {{ .Values.minioAccessKey }}
    - name: minio-secret-key
      value: {{ .Values.minioSecretKey }}
    - name: embeddings-status
      value: $(tasks.generate-embeddings.results.status)
    - name: elasticsearch-endpoint
      value: {{ .Values.elasticsearchEndpoint | quote }}
    - name: elasticsearch-username
      value: {{ .Values.elasticsearchUsername | quote }}
    - name: elasticsearch-password
      value: {{ .Values.elasticsearchPassword | quote }}