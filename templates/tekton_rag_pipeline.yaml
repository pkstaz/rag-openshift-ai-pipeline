apiVersion: tekton.dev/v1beta1
kind: Pipeline
metadata:
  name: {{ .Values.pipelineName }}
  namespace: {{ .Values.namespace }}
spec:
  params:
  - name: minio-endpoint
    default: "{{ .Values.minioEndpoint }}"
  - name: minio-access-key
    default: "{{ .Values.minioAccessKey }}"
  - name: minio-secret-key
    default: "{{ .Values.minioSecretKey }}"
  - name: bucket-name
    default: "{{ .Values.bucketName }}"
  - name: object-key
    default: "{{ .Values.objectKey }}"
  - name: chunk-size
    default: "{{ .Values.chunkSize }}"
  - name: chunk-overlap
    default: "{{ .Values.chunkOverlap }}"

  tasks:
  - name: extract-text
    taskSpec:
      params:
      - name: minio-endpoint
      - name: minio-access-key
      - name: minio-secret-key
      - name: bucket-name
      - name: object-key
      results:
      - name: text-content
        description: Extracted text content
      steps:
      - name: extract
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          
          import sys
          import tempfile
          import os
          
          print("ğŸš€ Starting text extraction...")
          print(f"ğŸ“Š Python version: {sys.version}")
          
          # Install required packages
          print("ğŸ“¦ Installing dependencies...")
          os.system("pip install --quiet minio requests")
          
          from minio import Minio
          
          try:
              print("ğŸ”— Connecting to MinIO...")
              print(f"Endpoint: $(params.minio-endpoint)")
              print(f"Bucket: $(params.bucket-name)")
              print(f"Object: $(params.object-key)")
              
              # Connect to MinIO
              minio_client = Minio(
                  "$(params.minio-endpoint)",
                  access_key="$(params.minio-access-key)",
                  secret_key="$(params.minio-secret-key)",
                  secure=True
              )
              
              # Test connection
              print("ğŸ§ª Testing MinIO connection...")
              try:
                  buckets = list(minio_client.list_buckets())
                  print(f"âœ… Connected! Found {len(buckets)} buckets")
                  for bucket in buckets:
                      print(f"  - {bucket.name}")
              except Exception as e:
                  print(f"âš ï¸ Warning: Could not list buckets: {e}")
              
              # Download file
              print("ğŸ“¥ Downloading file...")
              with tempfile.NamedTemporaryFile(delete=False, suffix='.txt') as temp_file:
                  temp_path = temp_file.name
              
              minio_client.fget_object("$(params.bucket-name)", "$(params.object-key)", temp_path)
              print(f"âœ… File downloaded to: {temp_path}")
              
              # Read content
              print("ğŸ“– Reading file content...")
              with open(temp_path, 'r', encoding='utf-8', errors='replace') as f:
                  content = f.read()
              
              # Clean up
              os.unlink(temp_path)
              
              print(f"âœ… Text extracted: {len(content)} characters")
              print(f"ğŸ“ Content preview: {content[:100]}...")
              
              # Ensure results directory exists
              os.makedirs("/tekton/results", exist_ok=True)
              
              # Write result to Tekton results
              result_path = "/tekton/results/text-content"
              with open(result_path, "w", encoding='utf-8') as f:
                  f.write(content)
              
              print(f"âœ… Result written to: {result_path}")
              print(f"ğŸ“Š Result file size: {os.path.getsize(result_path)} bytes")
                  
          except Exception as e:
              print(f"âŒ Error in extraction: {str(e)}")
              import traceback
              traceback.print_exc()
              
              # Write error as result
              os.makedirs("/tekton/results", exist_ok=True)
              error_msg = f"Error extracting text: {str(e)}"
              with open("/tekton/results/text-content", "w") as f:
                  f.write(error_msg)
              
              # Don't fail the task, just log the error
              print("âš ï¸ Error logged to results, continuing...")
        resources:
          requests:
            memory: 256Mi
            cpu: 100m
          limits:
            memory: 512Mi
            cpu: 200m
    params:
    - name: minio-endpoint
      value: $(params.minio-endpoint)
    - name: minio-access-key
      value: $(params.minio-access-key)
    - name: minio-secret-key
      value: $(params.minio-secret-key)
    - name: bucket-name
      value: $(params.bucket-name)
    - name: object-key
      value: $(params.object-key)

  - name: chunk-text
    runAfter: ["extract-text"]
    taskSpec:
      params:
      - name: text-content
        description: Text content from previous task
      - name: chunk-size
      - name: chunk-overlap
      results:
      - name: chunks-json
        description: JSON with text chunks
      steps:
      - name: chunk
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          
          import json
          import sys
          import os
          import base64
          
          print("ğŸš€ Starting chunking process...")
          print(f"ğŸ“Š Python version: {sys.version}")
          
          # Get text content from parameter (passed from previous task)
          text_content = """$(params.text-content)"""
          
          print(f"ğŸ“ Received text length: {len(text_content)} characters")
          print(f"ğŸ“„ Text preview: {text_content[:200]}...")
          
          try:
              chunk_size = int("$(params.chunk-size)")
              chunk_overlap = int("$(params.chunk-overlap)")
              
              print(f"âš™ï¸ Chunk size: {chunk_size}")
              print(f"âš™ï¸ Chunk overlap: {chunk_overlap}")
              
              if not text_content or text_content.strip() == "":
                  print("âš ï¸ Empty text content received")
                  chunks = []
              elif text_content.startswith("Error"):
                  print("âš ï¸ Error in previous task, creating error chunk")
                  chunks = [{
                      "chunk_id": "chunk_error",
                      "text": text_content,
                      "char_count": len(text_content),
                      "error": True
                  }]
              else:
                  # Chunking logic
                  max_chars = chunk_size * 4  # Conservative estimate
                  overlap_chars = chunk_overlap * 4
                  
                  chunks = []
                  start = 0
                  chunk_id = 0
                  
                  print(f"ğŸ”§ Calculated max_chars: {max_chars}, overlap_chars: {overlap_chars}")
                  
                  while start < len(text_content):
                      end = min(start + max_chars, len(text_content))
                      chunk_text = text_content[start:end]
                      
                      # Find good cut point at word boundary
                      if end < len(text_content):
                          space_pos = chunk_text.rfind(' ', int(len(chunk_text) * 0.8))
                          if space_pos > 0:
                              chunk_text = chunk_text[:space_pos]
                              end = start + space_pos
                      
                      chunk_text = chunk_text.strip()
                      if len(chunk_text) > 10:  # Skip very small chunks
                          chunk_data = {
                              "chunk_id": f"chunk_{chunk_id:04d}",
                              "text": chunk_text,
                              "char_count": len(chunk_text),
                              "start_pos": start,
                              "end_pos": start + len(chunk_text)
                          }
                          chunks.append(chunk_data)
                          chunk_id += 1
                          print(f"âœ… Created chunk {chunk_id}: {len(chunk_text)} chars")
                      
                      if end >= len(text_content):
                          break
                      start = max(end - overlap_chars, start + 1)
              
              # CREATE THE RESULT VARIABLE - This was missing!
              result = json.dumps(chunks, ensure_ascii=False)
              print(f"âœ… Created JSON result with {len(chunks)} chunks")
              
              # Encode result in base64 to avoid JSON control character issues
              result_b64 = base64.b64encode(result.encode('utf-8')).decode('ascii')
              
              # Write base64 encoded result
              os.makedirs("/tekton/results", exist_ok=True)
              result_path = "/tekton/results/chunks-json"
              with open(result_path, "w", encoding='utf-8') as f:
                  f.write(result_b64)
              
              print(f"âœ… Chunks written to: {result_path}")
              print(f"ğŸ“Š Result size: {len(result)} characters")
              print(f"ğŸ“Š Base64 size: {len(result_b64)} characters")
                  
          except Exception as e:
              print(f"âŒ Error in chunking: {str(e)}")
              import traceback
              traceback.print_exc()
              
              # Fallback chunk with base64 encoding
              fallback = [{
                  "chunk_id": "chunk_error_0000",
                  "text": text_content[:1000] if text_content else "No content available",
                  "char_count": len(text_content[:1000]) if text_content else 0,
                  "error": True,
                  "error_message": str(e)
              }]
              
              fallback_result = json.dumps(fallback, ensure_ascii=False)
              fallback_b64 = base64.b64encode(fallback_result.encode('utf-8')).decode('ascii')
              
              os.makedirs("/tekton/results", exist_ok=True)
              with open("/tekton/results/chunks-json", "w") as f:
                  f.write(fallback_b64)
              
              print("âš ï¸ Fallback chunk created")
        resources:
          requests:
            memory: 128Mi
            cpu: 50m
          limits:
            memory: 256Mi
            cpu: 100m
    params:
    - name: text-content
      value: $(tasks.extract-text.results.text-content)
    - name: chunk-size
      value: $(params.chunk-size)
    - name: chunk-overlap
      value: $(params.chunk-overlap)

  - name: generate-embeddings
    runAfter: ["chunk-text"]
    taskSpec:
      params:
      - name: chunks-json
        description: JSON with chunks from previous task
      - name: minio-endpoint
      - name: minio-access-key
      - name: minio-secret-key
      - name: object-key
      results:
      - name: status
        description: Processing status
      steps:
      - name: embed
        image: python:3.9
        script: |
          #!/usr/bin/env python3
          
          import json
          import sys
          import os
          import base64
          import tempfile
          from datetime import datetime
          
          print("ğŸš€ Starting embedding generation...")
          print(f"ğŸ“Š Python version: {sys.version}")
          
          # Install required packages
          print("ğŸ“¦ Installing dependencies...")
          os.system("pip install --quiet sentence-transformers torch numpy minio")
          
          from sentence_transformers import SentenceTransformer
          import torch
          from minio import Minio
          
          # Get chunks from parameter - decode base64
          chunks_json_b64 = "$(params.chunks-json)"
          
          print(f"ğŸ“ Received base64 chunks length: {len(chunks_json_b64)} characters")
          
          try:
              # Decode from base64
              chunks_json = base64.b64decode(chunks_json_b64).decode('utf-8')
              print(f"ğŸ“ Decoded JSON length: {len(chunks_json)} characters")
              
              chunks = json.loads(chunks_json)
              print(f"ğŸ“Š Processing {len(chunks)} chunks")
              
              # Connect to MinIO for result storage
              print("ğŸ”— Connecting to MinIO for result storage...")
              minio_client = Minio(
                  "$(params.minio-endpoint)",
                  access_key="$(params.minio-access-key)",
                  secret_key="$(params.minio-secret-key)",
                  secure=True
              )
              
              result_status = "success"
              
              if not chunks:
                  print("âš ï¸ No chunks to process")
                  result = json.dumps([])
                  result_status = "no_chunks"
              elif any(chunk.get('error', False) for chunk in chunks):
                  print("âš ï¸ Error chunks detected, skipping embedding generation")
                  result = chunks_json  # Pass through the error chunks
                  result_status = "error_chunks"
              else:
                  # Load model with CPU only to avoid GPU issues
                  device = 'cpu'
                  print(f"ğŸ§  Loading model on {device}...")
                  model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2', device=device)
                  print(f"âœ… Model loaded successfully")
                  
                  # Generate embeddings
                  texts = [chunk['text'] for chunk in chunks]
                  print(f"ğŸ”„ Generating embeddings for {len(texts)} texts...")
                  
                  embeddings = model.encode(
                      texts, 
                      convert_to_numpy=True, 
                      normalize_embeddings=True,
                      show_progress_bar=True,
                      batch_size=8  # Small batch size to avoid memory issues
                  )
                  
                  # Add embeddings to chunks
                  for i, chunk in enumerate(chunks):
                      chunk['embedding'] = embeddings[i].tolist()
                      chunk['embedding_dim'] = len(embeddings[i])
                      chunk['embedding_model'] = 'sentence-transformers/all-MiniLM-L6-v2'
                  
                  result = json.dumps(chunks, ensure_ascii=False, indent=2)
                  print(f"ğŸ‰ Successfully generated embeddings for {len(chunks)} chunks")
              
              # Save result to MinIO instead of Tekton results (too large)
              print(f"ğŸ“¤ Uploading result to MinIO...")
              print(f"ğŸ“Š Result size: {len(result)} characters ({len(result.encode('utf-8'))} bytes)")
              
              # Create filename based on original object
              original_object = "$(params.object-key)"
              timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
              result_filename = f"embeddings/{original_object}_{timestamp}_embeddings.json"
              
              # Upload to MinIO
              with tempfile.NamedTemporaryFile(mode='w', encoding='utf-8', delete=False) as temp_file:
                  temp_file.write(result)
                  temp_path = temp_file.name
              
              try:
                  minio_client.fput_object("processed-documents", result_filename, temp_path)
                  print(f"âœ… Result uploaded to MinIO: processed-documents/{result_filename}")
                  
                  # Clean up
                  os.unlink(temp_path)
                  
                  # Create small status result for Tekton
                  status_result = {
                      "status": result_status,
                      "chunks_processed": len(chunks),
                      "result_location": f"minio://processed-documents/{result_filename}",
                      "result_size_bytes": len(result.encode('utf-8')),
                      "timestamp": timestamp
                  }
                  
                  # Write small status to Tekton results (this will fit in 4KB limit)
                  os.makedirs("/tekton/results", exist_ok=True)
                  status_path = "/tekton/results/status"
                  with open(status_path, "w", encoding='utf-8') as f:
                      f.write(json.dumps(status_result, ensure_ascii=False))
                  
                  print(f"âœ… Status written to Tekton results: {status_path}")
                  print(f"ğŸ“Š Status size: {len(json.dumps(status_result))} characters")
                  
              except Exception as upload_error:
                  print(f"âŒ Error uploading to MinIO: {upload_error}")
                  os.unlink(temp_path)
                  raise upload_error
                  
          except Exception as e:
              print(f"âŒ Error in embedding generation: {str(e)}")
              import traceback
              traceback.print_exc()
              
              # Fallback status
              fallback_status = {
                  "status": "error",
                  "error_message": str(e),
                  "chunks_processed": 0,
                  "timestamp": datetime.now().strftime("%Y%m%d_%H%M%S")
              }
              
              os.makedirs("/tekton/results", exist_ok=True)
              with open("/tekton/results/status", "w") as f:
                  f.write(json.dumps(fallback_status, ensure_ascii=False))
              
              print("âš ï¸ Error status created")
        resources:
          requests:
            memory: 1Gi
            cpu: 200m
          limits:
            memory: 2Gi
            cpu: 500m
    params:
    - name: chunks-json
      value: $(tasks.chunk-text.results.chunks-json)
    - name: minio-endpoint
      value: $(params.minio-endpoint)
    - name: minio-access-key
      value: $(params.minio-access-key)
    - name: minio-secret-key
      value: $(params.minio-secret-key)
    - name: object-key
      value: $(params.object-key)